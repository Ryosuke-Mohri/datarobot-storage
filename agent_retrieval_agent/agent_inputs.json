{
    "knowledge_base": {
        "can_edit": true,
        "created_at": "2025-09-11T18:54:12.350029Z",
        "description": "A variety of developer documents",
        "files": [
            {
                "created_at": "2025-09-11T18:54:31.266244Z",
                "encoded_content": {
                    "1": "# The `RELEASE.yaml` File\n\nThis file is both notational for the Development and Release teams and\nused by automation to perform code freeze branching for on-prem\nreleases.  See the\n[latest spec](https://datarobot.atlassian.net/wiki/spaces/Ignite/pages/5618761738/Distributed+Release+Metadata+-+RELEASE.yaml)\n\n## General\n\nThe format of this file is based on YAML representation. Fields should all be text unless\notherwise directed.\n\nAll fields are required unless otherwise noted.\n\nThere is now only one major version 2.0. It is shown in use by being a\nfile called RELEASE.yaml that has replaced BRANCHING.yaml.\n\n### The Release Process\n\nThe presence of this file presumes your repository is shipped as part\nof our product. As a result the repo is subject to our Information\nSecurity Policy and requirements for ISO 27001 and SOC 2\ncompliance. This includes branch protections, correct permissions for\nbranch-admins, etc as stated in the\n[Checklist for Production Software](https://datarobot.atlassian.net/wiki/spaces/Architecture/pages/5632426163).\n\nAdditionally, it means the repo will be branched as part of our\nEnterprise Release processes. This means it is subject to branching\nand tagging required for that process. Automations will discover\nRELEASE.yaml files and create `release/X.X` branches on each branch\ncut date. It will also create tags of the pattern\n`release/X.X-branchpoint`.  It will also create any additional tag\npatterns you specify in your RELEASE.yaml via the array of tags.\n\nBe sure to account for these patterns for common SCM release build\nsystems.\n\nAfter branch cut the file is also used to discover and identify\n[Acceptance Tests](https://datarobot.atlassian.net/wiki/spaces/Ignite/pages/5618925578/Acceptance+Testing+for+Multi-+Cloud+Repo)\nthat will run be automatically discovered and executed in our\nRegression Pipelines. At a future date, it may also execute\nPerformance Tests.\n\nThe third process we use RELEASE.yaml for is to continuously identify\nvulnerabilities and third-party libraries in our Enterprise product\n(Single Tenant SaaS, VPC, and On-Prem). We will pull in the specified\nTrivy Ignore Policy for your repo to reduce false positives, allow\nmanaged exceptions to discovered CVEs, and allow reviewed high risk\nthird party software such as GPL licensed packages in our base OS\nimages.\n\n### Dry Runs\n\nTo test our automation and continue developing and ensuring all repos are ready\nfor the Enterprise Release branch cut, we will periodically do dry runs. The dry runs will\ncreate branches and tags with a `-DRY-RUN` suffix added to the version, i.e., `10.0-DRY-RUN`.\n\n\n### Status\n\nAt this time (2024-04-03) version 2.0 features are fully\nsupported. Regression pipelines now fully incorporate Acceptance Tests\nand Trivy ignore files for enterprise release.\n\n## Top-Level Keys\n\n\n### `description`\n\n> Version: 1.0\n\nThis is a free-form text field that describes the core purpose of the repository. It doesn't\nhave to be long, as the details of the repo should be in a README file. Instead, it should get the point\nacross in one or two sentences, and should make it clear why it's important to branch it.\n\n### `production`\n\n> Version: 2.0\n\nBoolean, allowed values are `true`|`false`.\n\nIf set to `false`, the repository will be excluded from any discovery process, i.e. for the branch cut,\nacceptance test scheduling, etc.\n\nIf not set at all, it defaults to `true`.\n\n### `meta`\n\n> Version: 1.0\n\n> *Optional*\n\nMeta document information. A dictionary of values with the following keys:\n\n* `version` - Provide a string that indicates the version of this format to use in semantic versioning form.\n  This field is implicitly the latest version based on the file name. Example: `1.0.0` or `2.0.1`\n\n### `artifact_build_job`\n\n> Version: 1.0 _ONLY_\n\n> *Optional*\n\nThe path to an HQ jenkins job that will be run to prepare artifacts on the new branch,\nafter the branch is cut.\n\n_Note_ The usage of this field was inconsistent and could appear spaces instead of underscores.\n\n### `artifact_prepare_job`\n\n> Version: 1.0 _ONLY_\n\n> *Optional*\n\nYet another one-off 1.0 way of specifying artifact build jobs. This is just a string.\n\n### `artifact_prepare_parameters`\n\n> Version: 1.0 _ONLY_\n\n> *Optional*\n\nGoes with [artifact_prepare_job](#artifact_prepare_job) A dictionary of name/value pairs\nto hand to the job.\n\n### `post_branch_cut_pipelines`\n\n> Version 2.0+\n\n> Optional\n\nA list of dictionaries that define the jobs that are run after the branch is cut. Each job is defined\nin terms of these parameters. All values in these parameters are variable-expanded\n(see [Variables](#Variables)).\n\n* `host` - The service host to use to kick off the job\n* `service` - The type of service to use to run the job (e.g. `jenkins`, `harness`, or `POST`)\n* `endpoint` - The job endpoint\n    * `<job-name>` for `jenkins`\n    * `<organization-name>/projects/<project-name>/pipelines/<pipeline-name>` for `harness`\n    * Any arbitary path for `POST`\n* `variables` - A dictionary of additional variables to pass to the endpoint\n\n### `artifact_build_parameters`\n\n> Version 1.0 ONLY\n\n> *Optional*\n\nA dictionary of parameters to pass to the [artifact_build_job](#artifact_build_job).\n\n\n### `additional_jobs_to_be_updated` (with or without underscores)\n\n> Version 1.0 ONLY\n\n> *Optional*\n\nA list of HQ Jenkins job paths equivalent to [artifact_build_job](#artifact_build_job).\nf you need to run secondary jobs, this is where they should be listed.\n\n### `master-pins`\n\n> REMOVED, Version 1.0 ONLY\n\n> *Optional*\n\nIgnored. Only used notationally for information on how to post-branch-cut update\nthe master branch.\n\n### `pins`\n\nLocal files that should be updated during branch cut (before the branch is locked).\n\nThe value is a list of dictionaries with the following entries:\n\n* `file` - The file to update, relative to the repository root. (_required_)\n* `value` - The value to overwrite the `file` with (_optional_; must be set if `command` unset)\n* `command` - The command to run against `file` (e.g. with `sed`) to replace the value (_optional_; must be set if `value` unset)\n\n### `tags`\n\n> Version 1.0\n\n> *Optional*\n\nWhen the repository is branched, before the branch is made public, tags can be added in git. By default\na tag will be added to the version on the base branch that was branched *from*, but no tag is added\nto the new branch.\n\nThe value is a list of dictionaries with the following keys:\n\n* `name` - A descriptive name (in version 2.0+ used as the tag \"message\") (_required_)\n* `value` - (Version: 2.0) the tag's label (the name seen by git users) (_required_ in 2.0+)\n* `git` - (Version: 1.0 ONLY) the git command to run, without \"git\" (e.g. `tag {}.0.1`) (_required_ in 1.0)\n\n### `future_proof_automation`\n\n> Version 1.0 ONLY\n\n> *Optional*\n\nA list of strings, notational only, no tooling uses this.\n\n### `trivy-policy`\n\n> Version 2.0\n\n> *Optional*\n\nThe path to the\n[Trivy Rego Policy](https://aquasecurity.github.io/trivy/v0.41/docs/scanner/misconfiguration/custom/)\nfor handling OSS Compliance and CVE exceptions.\n\n### `acceptance-tests`\n\n> Version 2.0\n\n> *Optional*\n\nA dictionary that defines the acceptance test pipeline to run against an\ninstalled platform to validate the software is working correctly per\n[PBMP-5670](https://docs.google.com/document/d/1uU_POHMTVFrcVVjO8y30ean0Gk93TUuU7ya-vRkwGkw/edit).\nEach pipeline is defined in terms of these parameters. All values in\nthese parameters are variable-expanded (see [Variables](#Variables)).\n\n* `host` - The service host to use to kick off the job\n* `service` - The type of service to use to run the job (i.e. `jenkins`, `harness`, or `POST`)\n* `endpoint` - The job endpoint\n    * `<job-name>` for `jenkins`\n    * `<organization-name>/projects/<project-name>/pipelines/<pipeline-name>` for `harness`\n    * Any arbitary path for `POST`\n* `variables` - A dictionary of additional variables to pass to the endpoint. See below the full list\nof available variables\n\n#### Harness examples:\nBasic with minimal amount of variables\n```yaml\nacceptance-tests:\n  service: harness\n  endpoint: CIIT/projects/awesome_project/pipelines/Independent_Acceptance_Tests\n  variables:\n    VERSION_REF: \"{version}\"\n    DATAROBOT_URL: \"{end_user_uri}\"\n    DATAROBOT_API_TOKEN: \"{app_admin_api_key}\"\n    DATAROBOT_USERNAME: \"{app_admin_username}\"\n```\nAdvanced with raw input-set from Harness.\n```yaml\nacceptance-tests:\n  service: harness\n  endpoint: CIIT/projects/awesome_project/pipelines/Independent_Acceptance_Tests\n  input_set:\n    pipeline:\n      identifier: Independent_Acceptance_Tests\n      template:\n        templateInputs:\n          properties:\n            ci:\n              codebase:\n                build:\n                  spec:\n                    type: branch\n                    spec:\n                      branch: \"{version}\"\n          stages:\n            - stage:\n              identifier: Get_Deployment_Info\n              type: Custom\n              variables:\n                - name: SERVICE_NAMESPACE\n                  type: String\n                  value: \"{namespace}\"\n              spec:\n                environment:\n                  environmentRef: \"{cluster_name}\"\n                  infrastructureDefinitions:\n                    - identifier: \"{environ_name}\"\n                      inputs:\n                        identifier: \"{environ_name}\"\n                        type: KubernetesDirect\n                        spec:\n                          namespace: \"{namespace}\"\n                          releaseName: \"{release_name}\"\n          variables:\n            - name: PARENT_PIPELINE_URL\n              type: String\n              value: \"{parent_pipeline_url}\"\n```\n#### Jenkins examples:\n```yaml\nacceptance-tests:\n  service: jenkins\n  endpoint: Run_Independent_Acceptance_Tests_Job\n  variables:\n    VERSION_REF: \"{version}\"\n    DATAROBOT_URL: \"{end_user_uri}\"\n    DATAROBOT_API_TOKEN: \"{app_admin_api_key}\"\n    DATAROBOT_USERNAME: \"{app_admin_username}\"\n```\n\n\n### `performance-tests`\n\n> Version 2.0\n\n> *Optional*\n\nA dictionary that defines performance pipeline (preferably Shrink) to run against a\ninstalled platform to validate the software is working correctly per\n[PBMP-5670](https://docs.google.com/document/d/1uU_POHMTVFrcVVjO8y30ean0Gk93TUuU7ya-vRkwGkw/edit).\nEach pipeline is defined in terms of these parameters. All values in\nthese parameters are variable-expanded (see [Variables](#Variables)).\n\n* `host` - The service host to use to kick off the job\n* `service` - The type of service to use to run the job (e.g. `shrink`, `jenkins`, `harness`, or `POST`)\n* `endpoint` - The job endpoint\n    * `mbtest` or `cicada` for `shrink`\n    * `<job-name>` for `jenkins`\n    * `<organization-name>/projects/<project-name>/pipelines/<pipeline-name>` for `harness`\n    * Any arbitary path for `POST`\nneeded for cost allocation\n* `variables` - A dictionary of additional variables to pass to the endpoint\n\n\n## Variables\n\nVariables are not included in the document, but they are provided as\ninput and referancable within RELEASE.yaml\n\nVariables in many input fields are substituted. A variable is in\nPython `format` syntax (e.g. `foo {bar}` which substitutes the\ncontents of the variable `bar` into the part of the string containing\n`{bar}`.\n\nOptionally, a vertical-bar, `|` can be used to separate a variable name from\na default value. This is most useful in the case of auto-generated parameters\nsuch as `pins_*` and `__*` as described below.\n\n### [empty string]\n\n> Version: 1.0 ONLY\n\nIdentical to `version`. This is written as `{}`.\n\n### `version`\n\n> Version: 2.0\n\nIdentical to `{major_version}`.`{minor_version}`\n\n### `major_version`\n\n> Version: 2.0\nThe current major version number (e.g. `9` from `9.1`).\n\n### `minor_version`\n\n> Version: 2.0\nThe current minor version number (e.g. `1` from `9.1`).\n\n### `repo`\n\n> Version: 2.0\nThe repository name being branched.\n\n### `other_repo_version`\n\n> Version: 1.0 ONLY\n\nA one-off secondary repository version to update.\n\n### `date`\n\n> Version: 2.0\nThe current date in ISO format (e.g. `2023-01-01`)\n\n### `end_user_uri`\n\n> Version: 2.0\n> Only as a variable of `acceptance-tests`\n\nThe URI of the cluster. By default, HTTPS and 443 are assumed, if scheme and\nport are not specified.\n\n### `app_admin_api_key`\n\n> Version: 2.0\n> Only as a variable of `acceptance-tests`\n\nThe admin API key for the app running on the cluster for acceptance tests.\n\n### `app_admin_username`\n\n> Version: 2.0\n> Only as a variable of `acceptance-tests`\n\nThe app admin username.\n\n### `parent_pipeline_url`\n\n> Version: 2.0\n> Only as a variable of `acceptance-tests`\n\nThe self-url of the release pipeline executing the acceptance tests. This has no real effect on tests and it's\nonly used for UX purposes, to keep the acceptance test -> parent release pipeline traceability, so it's highly\nrecommended to add it to your pipeline.\n\n### `pins_*`\n\n> Version 2.0\n\nAll of the data from this config that is stored under the `pins` entry can be used as\nvariable substitution values. If there is an entry like so:\n\n```YAML\npins:\n  - file: VERSION\n    value: {version}\n```\n\nThen you could use the variable, `pins_0_value`, to reference the `value` key of the first\n(0th) entry in `pins`.\n\n### `__*`\n\n> Version 2.0\n\nWhen the branch command is run, additional parameters can be specified, either via the\ncommand-line or an environment variable. These additional parameters are available\nusing the prefix `__`, with the following transformations:\n\n* Dashes (`-`) are replaced with underscores (`_`)\n* All letters are upcased.\n\nFor example, if the command used `--extra-parameters` for this purpose then this command-line:\n\n```\n$ branch --extra-parameters='thing-1=5,thing-2=6'\n```\n\nThen using the following in your config:\n\n```YAML\npins:\n  - file: VERSION\n    value: {__THING_1}\n```\n\nwould substitute in the value `5`.\n\n**IMPORTANT**: If a parameter is referenced, but not provided, an error will be thrown. No\nerror is thrown if a default value is provided in the config (e.g. `{__THING_1|0}`).\n\n## Examples\n\n### Version 1.0\n\n```YAML",
                    "2": "description: |\n  This is the example repository.\n  It contains examples that relate to specific releases.\n\nartifact_build_job: path/to/job/a\nartifact_build_job_type: jenkins-jobs\n\nartifact_build_parameters: {}\n\nadditional jobs to be updated:\n  - path/to/job/b\n  - path/to/job/c\n\nmaster-pins:\n  - file: ./VERSION\n    command: echo \"{version}.0\" > ./VERSION\n\npins:\n  - file: ./build.sh\n    command: sed -i s/--version master/--version {version}/ ./build.sh\n\ndependencies:\n  - name: other-repo\n    command: echo \"{other_repo_version}\" > deps/OTHER_REPO_VERSION\n```\n\n### Version 2.0\n\n```YAML",
                    "3": "description: |\n  This is the example repository.\n  It contains examples that relate to specific releases.\n\npins:\n  - file: project/Versioning.scala\n    command: \"sed -i s/master-dev/{version}/\"\n\n  - file: python/VERSION\n    value: \"{version}\"\n\npost_branch_cut_jobs:\n  - endpoint: /path/to/job\n    host: https://jenkins.example.com\n    service: jenkins\n    variables:\n      version: \"{version}\"\n      branch: \"release/{version}\"\n      branchpoint_tag: \"release/{version}-branchpoint\"\n\nacceptance-tests:\n  - endpoint: /path/to/job\n    host: https://jenkins.example.com\n    service: jenkins\n    variables:\n      api_url: \"{end_user_uri}\"\n      api_key: \"{app_admin_api_key}\"\n      sha: \"release/{version}\"\n      dr_username: \"{app_admin_username}\"\n      parent_pipeline_url: \"{parent_pipeline_url}\"\n\nperformance-tests:\n  - host: http://locust.example.com\n    service: shrink\n    endpoint: mbtest\n    variables:\n      description: \"MB RELEASE.yaml {version} test\"\n      predefined_dataset: variety_coverage.yaml\n\n  - host: http://locust.example.com\n    service: shrink\n    endpoint: cicada\n    variables:\n      description: \"Cicada RELEASE.yaml {version} test\"\n      test_options:\n        cicada_sha: \"origin/release/{version}\"\n        suit_name: webserver_test.py\n      cluster_options:\n        launch_type: aws\n        artifact:\n          artifact_type: new\n          datarobot_branch: origin/master\n        options:\n          platform: dockerized\n```"
                },
                "file_path": ".data/storage/uploads/1/fb0d2ebf-525b-4c0b-8805-17e9ce0c8e13/sample_yaml_spec.md",
                "filename": "sample_yaml_spec.md",
                "owner_uuid": "6b3823a1-82dc-4021-b3c9-19d38ffbe21d",
                "size_tokens": 4010,
                "source": "local",
                "uuid": "44887e8a-b7c0-4100-b202-413a8bed7418"
            },
            {
                "created_at": "2025-09-11T18:54:32.211716Z",
                "encoded_content": {
                    "1": " \nBroader support for non-Python apps \nTechnical Conversation \nAuthor: Ben Cutler \nTeam: Applications \nPreface \n\u25cf\u200b PBM Card Link: https://atlassian.net/browse/SPEC-2 \n\u25cf\u200b Product Requirements Document Link: \nhttps://docs.google.com/document/d/1FF-WJnQ-bjv7vZVi_LhbC8U9DMza2Nf2CU2eetTyegY/e\ndit?tab=t.0#heading=h.irewn75eusmk  \n\u25cf\u200b Product Manager: \n \nColleen Wilhide\nBackground \nWe have gotten large amounts of feedback from users and CFDS that there is strong demand for React \napps which we do not support. The apps platform does not support other languages (such as Javascript, \nor go, etc) because those languages install their dependencies differently than a python app. Rather than \nrequire customers build an execution environment bespoke to each package (in the case of JS, the \nenvironment would have the required node_modules) or upload a built binary of their app (in the case of a \ngo or Java app) it would make sense to provide users with some more functionality for building their app \nfrom source code to something they can run.  \nReferences \nA huge chunk of this work has been done thanks to Illia in this SPEC-1: \nhttps://atlassian.net/browse/SPEC-1 \nRationale \nCurrently users of the app platform can upload a requirements.txt to their custom apps source \nversion, but that\u2019s basically a point solution specifically for users who use Python and manage their \ndependencies via a requirements.txt file. We could build out a solution to also install a package.json file, \nbut then when users want to have their backend be Go we have support installing  go.mod files, then when \nusers want to build a go app *and* a react app we need another point solution and things just get dicey \nand don\u2019t scale. \n \n Version May 2022.Draft \n1 \n \n",
                    "10": " \nFeedback \nAdvice \nThis reflects the outputs from following the Conversations Advice Process. It is here that all advice \ngiven is recorded. This ought to include the name of the advice giver, and the date the advice was given. \nThis can frequently take the forms of comments, and if these are provided directly by the advice-giver, \nthey should use RFC 2119 key words to state their opinion. \n\u25cf\u200b MUST \n\u25cb\u200b \u2026 \n\u25cf\u200b SHOULD \n\u25cb\u200b Fill out the Technical Specification Process feedback form to help the process improve \n\u25cf\u200b MAY \n\u25cb\u200b \u2026 \nRejected Advice \nThroughout the discussion of a design, various ideas will be proposed which are not accepted. Those \nrejected ideas should be recorded along with the reasoning as to why they were rejected. This both \nhelps record the thought process behind the final version of the design as well as preventing people \nfrom bringing up the same rejected idea again in subsequent discussions. \n \nTemplate version: 2022-08-12 \n \n \n \n \n Version May 2022.Draft \n10 \n \n",
                    "2": "Unset\nUnset\n \nRather than build more point solutions, we want to build a more all-purpose approach for users to build \ntheir own apps. \nWe also want to remove the limitation on running apps on the /apps/<id> path, while we can run Flask \napps via gunicorn, it\u2019s an awkward limitation that could cause hangups and confusion.  \nOut of scope \n\u25cf\u200b Direct Docker upload apps.  \nStakeholders \n\u25cf\u200b Product: \n \nColleen Wilhide\n\u25cf\u200b Custom Models : \n  \nBogdan Klichuk\n\u25cf\u200b Apps: \n \nRaul Pineda\n\u25cf\u200b Security: \n Can you help me assign someone to this?  \nJoe D'Agostino\n \nLogical Architecture \nThe way the custom model dependency parser is set up, we basically call:\u200b\n \n   parser = BaseDependencyParserService.get_requirements_parser(language) \nWhich gets a parser on a per-language basis, and we have a set of supported languages: \nhttps://github.com/datarobot/DataRobot/blob/5e0abf3470f113450107378a4477cca78e29cb56/raptor\n_lake/dependencies/services.py#L66-L95 \nThen we call a parser method to generate a big command:\u200b\nhttps://github.com/datarobot/DataRobot/blob/5e0abf3470f113450107378a4477cca78e29cb56/raptor\n_lake/dependencies/services.py#L396-L424 \nIn the case of a custom app with a requirements.txt, this string would be a look something like:\u200b\n \n[ \"RUN pip install foo=1.2.3 bar==3.4.5 jazz=10.2\"]  \n \n \n Version May 2022.Draft \n2 \n \n",
                    "3": "Unset\n \nAnd that would be passed into here: \nhttps://github.com/repo/code.py#L205 \n\u200b\nA high level overview of the change would be: \n1.\u200b Instead of saying \u201cIf we have a requirements.txt do X\u201d, we say: \na.\u200b \u201cIf we have (see Architecture Decisions -> Considered options for interface), do Y \nb.\u200b else if we have requirements.txt, do X, (Don\u2019t break the existing flow) \nc.\u200b Otherwise just use the default env as is\u200b\n \nArchitecture Decisions  \nEditor\u2019s Note: Everything below this headline is optional if you are writing CAD (Conceptual Architecture \nDesign) \nConsidered options for interface \nOption A: Use a build-app.sh to compliment the start-app.sh script \nOne option for the interface here is to allow users to supply a build-app script where we have. For a go \napp with a react frontend, we could have the build-app be something like:\u200b\n \ngo build . \u200b\nnpm install .  \nAnd then that binary and node_packages are part of the build.  \n\u25cf\u200b [Good] Probably easy for customers to write their own build scripts.  \n\u25cf\u200b [NOTE] There is an image cache for the dependency file, and we need to figure that out so we \ndon\u2019t use old image. \u200b\n \nOption B: Have users supply a dockerfile  \nOne option for the interface here is to allow a user to make their own dockerfiles\u200b\n \n \n Version May 2022.Draft \n3 \n \n",
                    "4": "Unset\n \nRUN go build . -o myapp\u200b\nRUN npm install \nEXPOSE 5321 (Could we make this work??)\u200b\nENTRYPOINT myapp \nAnd then that binary is part of the build.   \n\u25cf\u200b [Good] Could be SUPER robust and awesome.  \n\u25cf\u200b [Good] Would make it much easier to to move customers off of the direct docker image upload \n\u25cf\u200b [Good] Lets customers build more complex / multistage apps which could be really useful.  \n\u25cf\u200b [Bad] Could introduce a can of security issues? If you do FROM and another customers\u2019 image ID, \nwhat happens? Can there be Kyverno errors if users mess with the users? If you EXPOSE a port, \nwhat does that do (Probably nothing) Maybe this is a solved problem already though since the \nsame issue should exist for execution environments. I\u2019m a little worried this sounds like a cool \nsolution when in reality, we don\u2019t get any tangible benefits. \nOption C: Extend the existing language tooling \nPart of the env flow is: If it\u2019s a python app (we know it\u2019s python because it is tagged as such on the env), \nwe build the requirements.txt \nThis could be extended to allow execution envs to be multi-language, and we do a build check for each \nof those languages. \n\u25cf\u200b [Good] If the docker build step does not have access to the context (eg a package.json) this \nsolution should still work .  \n\u25cf\u200b [Good] Probably more secure since users can\u2019t run arbitrary code in the build step.  \n\u25cf\u200b [Bad] for languages like python, we can do pip install yada=1.0.0 \nsomethingelse=1.2.3, etc, but there\u2019s no guarantee that approach will work for all \nlanguages. \n\u25cf\u200b [Bad] Less functionality available for users.  \nDecisions \nWe like Option A the most. Using existing tooling (Option C) requires us to do more work to scale the \nproduct, and there\u2019s no guarantee we\u2019ll be able to support every use case. Option B sounds cool, but if \nusers want to do zany stuff they can build zany execution environments. Requiring a custom dockerfile \nmakes it awkward to do a FROM and select your base image, and it makes it hard to develop with.  \nConsidered options for Apps on \u2018/\u2019 \nCurrently, the app ingress exposes /apps/<app-id> and that means that your app has to accept \nresponses on that url . \n \n Version May 2022.Draft \n4 \n \n",
                    "5": "Unset\nUnset\n \nThis is because when we send a request to an app, we need to reference a single ingress. If all your \napps run on the same domain and the same path, there\u2019s no way to specify one app that you want to \nsend requests to. \n We have UVICORN_ROOT_PATH as an env var which plugs into gunicorn and streamlit, so those work out \nof the box, but not every user knows about this, and it can be a barrier to adding apps. We would likely \nneed to add some kind of checkbox to the apps (under resources most likely) so we don\u2019t break \nexisting apps. \nIt is worth noting that on-prem, we don\u2019t need to run apps on `/apps/id` because we use the service \nURL, which is distinct already.  These changes are all for envs where we have LRS ingresses.  \nOption A: nginx path re-writing \nThis would involve having the nginx ingress do a path re-write from /apps/id \u2192 /. This is something I \nhave tested, all you need to do is add an annotation to the ingress and you\u2019re off to the races \n\u25cf\u200b [Good] Really easy to do!  \n\u25cf\u200b [Bad] Couples us more tightly with nginx. \nOption B: Apps on Domains \nCurrently, apps run on a URL like \nhttp://<basic-auth-user>@<basic-auth-pw>@eksX.int.foo.bar.datarobot.com:8080/apps/<id> \nAnd instead of having the path (/apps/id) be a way to reference a single app, we would use a domain, \nsuch as: \n \nhttp://<basic-auth-user>@<basic-auth-pw>@eksX.appId.int.foo.bar.datarobot.com:8080/ \nThat way we still have distinct URLs, but the domain is what is different.  \nWe will need to adjust the fqdn in the code \nHowever, the logic to get a cluster looks pretty rigid. Maybe we can just say fqdn = app.id +  \nfqdn  and we\u2019re good, but probably not.  \n\u25cf\u200b [Good] Would also work!  \n\u25cf\u200b [Bad] Might not be technically feasible, \n\u25cf\u200b [Bad] Can\u2019t really test on localdev or in a regression env. We need to test on stg which has a \nslow feedback cycle.  \n \n Version May 2022.Draft \n5 \n \n",
                    "6": "Unset\nUnset\n \n\u25cf\u200b [Bad] Might be difficult to get certs working if we have a whole bunch of domains \n\u25cf\u200b [NOTE] Talk to Erik L about the issue the apps conductor had with domains.  \nOption C: Apps on Ports  \nAs mentioned in Option B, apps run on a URL like \nhttp://<basic-auth-user>@<basic-auth-pw>@eksX.int.foo.bar.example.com:8080/apps/<id> \nWe can just run each app on its own port:\u200b\n \nhttp://<basic-auth-user>@<basic-auth-pw>@eksX.int.foo.bar.example.com:8081/\u200b\nhttp://<basic-auth-user>@<basic-auth-pw>@eksX.int.foo.bar.example.com:8082/\u200b\n<etc> \n \n\u25cf\u200b [Good] Easy!  \n\u25cf\u200b [Bad] If each customer has 20 apps, then we can only support ~3,200 customers (or about \n63,000 apps since there are reserved ports)  \n\u25cf\u200b [Bad] We shouldn\u2019t do this.  \nDecisions \nOption C is not gonna happen. I\u2019m worried that option B (apps on Domains) could cause things to break \nwith SSL certs, or the path not being allowed. Option A I have tested and it will work without causing \nany risks. If there\u2019s a major issue we can move to option B in the future.  \nOpen Issues/Risks/Questions \n\u25cf\u200b [Unknown] Is the build-context from the custom apps source version available when we build the \napp? \n\u25cf\u200b [Risk] Are there security issues about running arbitrary code / customer code in the build \nworker? \nObservability \nMeasuring Feature Success \nWe will see: \n1.\u200b Customers building more execution environments \n \n Version May 2022.Draft \n6 \n \n",
                    "7": " \n2.\u200b Customers building + using + sharing more apps \n3.\u200b CFDS making more apps with tools other than streamlit for services and templates \n4.\u200b A new app template for something like React JS which we support.  \nMonitoring/Alerting \nApps canary job + integration test should be extended to test this functionality \nData Qualities \nDatabase Indexes and Collections \nNo new changes to mongo \nData Models \nN/A \nData Regimes \nN/A \nData Replication \nN/A \nData Retention/PermaDelete \nWe will still be storing images in our image store just like normal. We do not have perma delete set up \nat the moment.  \nData Backup/Restore \nThings should work with reverting deleted apps if needed.  \nEffectiveness \nResources and cost \n\u25cf\u200b The build effort is probably a single PR  \n\u25cf\u200b The app's path on / effort is up in the air, but likely not difficult.  \n \n Version May 2022.Draft \n7 \n \n",
                    "8": " \nCompatibility \nApps on / will need to be a toggleable feature so we don\u2019t break existing apps which may be setup to run \non /apps/id  \nThe build process will need to make sure existing apps still build a requirements.txt if that is supplied.  \nScalability \nN/A \nSecurity Considerations \n\u25cf\u200b Is running the build script safe in our environment?  \n\u25cf\u200b Do dockerfiles have access to undesired things in their docker context, such as the DR source \ncode? Can I COPY <DataRobot source> .in a dockerfile, or do a requests.post all the files \nin the container to a remote location?  \nLegal Considerations \nN/A \nIntellectual Property (IP) \nN/A \nMaintainability: Code Ownership \nAll code added will be owned by the Apps team. \nMilestones \nMilestone 1:  \nApps on / . To mark this as done: we need to test + verify that you can run an app on / in ST SAAS (We \nshould test all 4 regression environments + staging) \nMilestone 2:  \nMore complex environments. We can mark this as done when we can run a react app on / on all 4 \nregression envs + staging.  \n \n \n Version May 2022.Draft \n8 \n \n",
                    "9": " \nPossible Future Work \n \nBased on the current product requirements and proposed technical design, describe any future \ntechnical changes or enhancements which are reasonable to expect or imagine for the systems \ninvolved in this technical design. \n \n \n Version May 2022.Draft \n9 \n \n"
                },
                "file_path": ".data/storage/uploads/1/fb0d2ebf-525b-4c0b-8805-17e9ce0c8e13/sample_tech_spec.pdf",
                "filename": "sample_tech_spec.pdf",
                "owner_uuid": "6b3823a1-82dc-4021-b3c9-19d38ffbe21d",
                "size_tokens": 3270,
                "source": "local",
                "uuid": "6e54665e-9c84-4ac6-a2b0-1415f492c72b"
            },
            {
                "created_at": "2025-09-11T18:54:32.975776Z",
                "encoded_content": {
                    "1": "Broader support for non-Python apps\nTechnical Conversation\nAuthor: Ben Cutler\nTeam: Applications\nPreface\nPBM Card Link: https://atlassian.net/browse/SPEC-2\nProduct Requirements Document Link: https://docs.google.com/document/d/1FF-WJnQ-bjv7vZVi_LhbC8U9DMza2Nf2CU2eetTyegY/edit?tab=t.0#heading=h.irewn75eusmk \nProduct Manager: Colleen Wilhide\nBackground\nWe have gotten large amounts of feedback from users and CFDS that there is strong demand for React apps which we do not support. The apps platform does not support other languages (such as Javascript, or go, etc) because those languages install their dependencies differently than a python app. Rather than require customers build an execution environment bespoke to each package (in the case of JS, the environment would have the required node_modules) or upload a built binary of their app (in the case of a go or Java app) it would make sense to provide users with some more functionality for building their app from source code to something they can run. \nReferences\nA huge chunk of this work has been done thanks to Illia in this SPEC-1: https://atlassian.net/browse/SPEC-1\nRationale\nCurrently users of the app platform can upload a requirements.txt to their custom apps source version, but that\u2019s basically a point solution specifically for users who use Python and manage their dependencies via a requirements.txt file. We could build out a solution to also install a package.json file, but then when users want to have their backend be Go we have support installing  go.mod files, then when users want to build a go app *and* a react app we need another point solution and things just get dicey and don\u2019t scale.\nRather than build more point solutions, we want to build a more all-purpose approach for users to build their own apps.\nWe also want to remove the limitation on running apps on the /apps/<id> path, while we can run Flask apps via gunicorn, it\u2019s an awkward limitation that could cause hangups and confusion. \nOut of scope\nDirect Docker upload apps. \nStakeholders\nProduct: Colleen Wilhide\nCustom Models : Bogdan Klichuk \nApps: Raul Pineda\nSecurity: Joe D'Agostino Can you help me assign someone to this? \n\nLogical Architecture\nThe way the custom model dependency parser is set up, we basically call:\n\n\uec03   parser = BaseDependencyParserService.get_requirements_parser(language)\n\uec02Which gets a parser on a per-language basis, and we have a set of supported languages:\nhttps://github.com/datarobot/DataRobot/blob/5e0abf3470f113450107378a4477cca78e29cb56/raptor_lake/dependencies/services.py#L66-L95\nThen we call a parser method to generate a big command:\nhttps://github.com/datarobot/DataRobot/blob/5e0abf3470f113450107378a4477cca78e29cb56/raptor_lake/dependencies/services.py#L396-L424\nIn the case of a custom app with a requirements.txt, this string would be a look something like:\n\n\uec03[ \"RUN pip install foo=1.2.3 bar==3.4.5 jazz=10.2\"] \n\uec02\nAnd that would be passed into here:\nhttps://github.com/repo/code.py#L205\n\nA high level overview of the change would be:\nInstead of saying \u201cIf we have a requirements.txt do X\u201d, we say:\n\u201cIf we have (see Architecture Decisions -> Considered options for interface), do Y\nelse if we have requirements.txt, do X, (Don\u2019t break the existing flow)\nOtherwise just use the default env as is\n\nArchitecture Decisions \nEditor\u2019s Note: Everything below this headline is optional if you are writing CAD (Conceptual Architecture Design)\nConsidered options for interface\nOption A: Use a build-app.sh to compliment the start-app.sh script\nOne option for the interface here is to allow users to supply a build-app script where we have. For a go app with a react frontend, we could have the build-app be something like:\n\n\uec03go build . \nnpm install . \n\uec02And then that binary and node_packages are part of the build. \n[Good] Probably easy for customers to write their own build scripts. \n[NOTE] There is an image cache for the dependency file, and we need to figure that out so we don\u2019t use old image. \n\nOption B: Have users supply a dockerfile \nOne option for the interface here is to allow a user to make their own dockerfiles\n\n\uec03RUN go build . -o myapp\nRUN npm install\nEXPOSE 5321 (Could we make this work??)\nENTRYPOINT myapp\n\uec02And then that binary is part of the build.  \n[Good] Could be SUPER robust and awesome. \n[Good] Would make it much easier to to move customers off of the direct docker image upload\n[Good] Lets customers build more complex / multistage apps which could be really useful. \n[Bad] Could introduce a can of security issues? If you do FROM and another customers\u2019 image ID, what happens? Can there be Kyverno errors if users mess with the users? If you EXPOSE a port, what does that do (Probably nothing) Maybe this is a solved problem already though since the same issue should exist for execution environments. I\u2019m a little worried this sounds like a cool solution when in reality, we don\u2019t get any tangible benefits.\nOption C: Extend the existing language tooling\nPart of the env flow is: If it\u2019s a python app (we know it\u2019s python because it is tagged as such on the env), we build the requirements.txt\nThis could be extended to allow execution envs to be multi-language, and we do a build check for each of those languages.\n[Good] If the docker build step does not have access to the context (eg a package.json) this solution should still work . \n[Good] Probably more secure since users can\u2019t run arbitrary code in the build step. \n[Bad] for languages like python, we can do pip install yada=1.0.0 somethingelse=1.2.3, etc, but there\u2019s no guarantee that approach will work for all languages.\n[Bad] Less functionality available for users. \nDecisions\nWe like Option A the most. Using existing tooling (Option C) requires us to do more work to scale the product, and there\u2019s no guarantee we\u2019ll be able to support every use case. Option B sounds cool, but if users want to do zany stuff they can build zany execution environments. Requiring a custom dockerfile makes it awkward to do a FROM and select your base image, and it makes it hard to develop with. \nConsidered options for Apps on \u2018/\u2019\nCurrently, the app ingress exposes /apps/<app-id> and that means that your app has to accept responses on that url .\nThis is because when we send a request to an app, we need to reference a single ingress. If all your apps run on the same domain and the same path, there\u2019s no way to specify one app that you want to send requests to.\n We have UVICORN_ROOT_PATH as an env var which plugs into gunicorn and streamlit, so those work out of the box, but not every user knows about this, and it can be a barrier to adding apps. We would likely need to add some kind of checkbox to the apps (under resources most likely) so we don\u2019t break existing apps.\nIt is worth noting that on-prem, we don\u2019t need to run apps on `/apps/id` because we use the service URL, which is distinct already.  These changes are all for envs where we have LRS ingresses. \nOption A: nginx path re-writing\nThis would involve having the nginx ingress do a path re-write from /apps/id \u2192 /. This is something I have tested, all you need to do is add an annotation to the ingress and you\u2019re off to the races\n[Good] Really easy to do! \n[Bad] Couples us more tightly with nginx.\nOption B: Apps on Domains\nCurrently, apps run on a URL like\n\uec03http://<basic-auth-user>@<basic-auth-pw>@eksX.int.foo.bar.datarobot.com:8080/apps/<id>\n\uec02And instead of having the path (/apps/id) be a way to reference a single app, we would use a domain, such as:\n\n\uec03http://<basic-auth-user>@<basic-auth-pw>@eksX.appId.int.foo.bar.datarobot.com:8080/\n\uec02That way we still have distinct URLs, but the domain is what is different. \nWe will need to adjust the fqdn in the code\nHowever, the logic to get a cluster looks pretty rigid. Maybe we can just say fqdn = app.id +  fqdn  and we\u2019re good, but probably not. \n[Good] Would also work! \n[Bad] Might not be technically feasible,\n[Bad] Can\u2019t really test on localdev or in a regression env. We need to test on stg which has a slow feedback cycle. \n[Bad] Might be difficult to get certs working if we have a whole bunch of domains\n[NOTE] Talk to Erik L about the issue the apps conductor had with domains. \nOption C: Apps on Ports \nAs mentioned in Option B, apps run on a URL like\n\uec03http://<basic-auth-user>@<basic-auth-pw>@eksX.int.foo.bar.example.com:8080/apps/<id>\n\uec02We can just run each app on its own port:\n\n\uec03http://<basic-auth-user>@<basic-auth-pw>@eksX.int.foo.bar.example.com:8081/\nhttp://<basic-auth-user>@<basic-auth-pw>@eksX.int.foo.bar.example.com:8082/\n<etc>\n\uec02\n[Good] Easy! \n[Bad] If each customer has 20 apps, then we can only support ~3,200 customers (or about 63,000 apps since there are reserved ports) \n[Bad] We shouldn\u2019t do this. \nDecisions\nOption C is not gonna happen. I\u2019m worried that option B (apps on Domains) could cause things to break with SSL certs, or the path not being allowed. Option A I have tested and it will work without causing any risks. If there\u2019s a major issue we can move to option B in the future. \nOpen Issues/Risks/Questions\n[Unknown] Is the build-context from the custom apps source version available when we build the app?\n[Risk] Are there security issues about running arbitrary code / customer code in the build worker?\nObservability\nMeasuring Feature Success\nWe will see:\nCustomers building more execution environments\nCustomers building + using + sharing more apps\nCFDS making more apps with tools other than streamlit for services and templates\nA new app template for something like React JS which we support. \nMonitoring/Alerting\nApps canary job + integration test should be extended to test this functionality\nData Qualities\nDatabase Indexes and Collections\nNo new changes to mongo\nData Models\nN/A\nData Regimes\nN/A\nData Replication\nN/A\nData Retention/PermaDelete\nWe will still be storing images in our image store just like normal. We do not have perma delete set up at the moment. \nData Backup/Restore\nThings should work with reverting deleted apps if needed. \nEffectiveness\nResources and cost\nThe build effort is probably a single PR \nThe app's path on / effort is up in the air, but likely not difficult. \nCompatibility\nApps on / will need to be a toggleable feature so we don\u2019t break existing apps which may be setup to run on /apps/id \nThe build process will need to make sure existing apps still build a requirements.txt if that is supplied. \nScalability\nN/A\nSecurity Considerations\nIs running the build script safe in our environment? \nDo dockerfiles have access to undesired things in their docker context, such as the DR source code? Can I COPY <DataRobot source> .in a dockerfile, or do a requests.post all the files in the container to a remote location? \nLegal Considerations\nN/A\nIntellectual Property (IP)\nN/A\nMaintainability: Code Ownership\nAll code added will be owned by the Apps team.\nMilestones\nMilestone 1: \nApps on / . To mark this as done: we need to test + verify that you can run an app on / in ST SAAS (We should test all 4 regression environments + staging)\nMilestone 2: \nMore complex environments. We can mark this as done when we can run a react app on / on all 4 regression envs + staging. \n\nPossible Future Work\n\nBased on the current product requirements and proposed technical design, describe any future technical changes or enhancements which are reasonable to expect or imagine for the systems involved in this technical design.\n\nFeedback\nAdvice\nThis reflects the outputs from following the Conversations Advice Process. It is here that all advice given is recorded. This ought to include the name of the advice giver, and the date the advice was given. This can frequently take the forms of comments, and if these are provided directly by the advice-giver, they should use RFC 2119 key words to state their opinion.\nMUST\n\u2026\nSHOULD\nFill out the Technical Specification Process feedback form to help the process improve\nMAY\n\u2026\nRejected Advice\nThroughout the discussion of a design, various ideas will be proposed which are not accepted. Those rejected ideas should be recorded along with the reasoning as to why they were rejected. This both helps record the thought process behind the final version of the design as well as preventing people from bringing up the same rejected idea again in subsequent discussions.\n\nTemplate version: 2022-08-12"
                },
                "file_path": ".data/storage/uploads/1/fb0d2ebf-525b-4c0b-8805-17e9ce0c8e13/sample_tech_spec.docx",
                "filename": "sample_tech_spec.docx",
                "owner_uuid": "6b3823a1-82dc-4021-b3c9-19d38ffbe21d",
                "size_tokens": 3074,
                "source": "local",
                "uuid": "0e1f9814-1dda-4072-9fc9-24645f8785bf"
            },
            {
                "created_at": "2025-09-11T18:54:33.775582Z",
                "encoded_content": {
                    "1": "# Talk to My Data  \n\n**Talk to My Data** delivers a seamless **talk-to-your-data** experience, transforming files, spreadsheets, and cloud data into actionable insights. Simply upload data, connect to Snowflake or BigQuery, or access datasets from DataRobot's Data Registry. Then, ask a question, and the agent recommends business analyses, generating **charts, tables, and even code** to help you interpret the results.  \n\nThis intuitive experience is designed for **scalability and flexibility**, ensuring that whether you're working with a few thousand rows or billions, your data analysis remains **fast, efficient, and insightful**.  \n\n\n> [!WARNING]\n> Application templates are intended to be starting points that provide guidance on how to develop, serve, and maintain AI applications.\n> They require a developer or data scientist to adapt and modify them for their business requirements before being put into production.\n\n![Using the \"Talk to My Data\" agent](https://s3.us-east-1.amazonaws.com/datarobot_public/drx/recipe_gifs/launch_gifs/talktomydata.gif)\n\n\n## Table of contents\n1. [Setup](#setup)\n2. [Architecture overview](#architecture-overview)\n3. [Why build AI Apps with DataRobot app templates?](#why-build-ai-apps-with-datarobot-app-templates)\n4. [Data privacy](#data-privacy)\n5. [Make changes](#make-changes)\n   - [Change the frontend](#change-the-frontend)\n   - [Change the LLM](#change-the-llm)\n   - [Change the database](#change-the-database)\n      * [Snowflake](#snowflake)\n      * [BigQuery](#bigquery)\n6. [Tools](#tools)\n7. [Share results](#share-results)\n8. [Delete all provisioned resources](#delete-all-provisioned-resources)\n9. [Setup for advanced users](#setup-for-advanced-users)\n\n## Setup\n\nBefore proceeding, ensure you have access to the required credentials and services. This template is pre-configured to use an Azure OpenAI endpoint and Snowflake Database credentials. To run the template as-is, you will need access to Azure OpenAI (leverages `gpt-4o` by default). \n\nCodespace users can **skip steps 1 and 2**. For local development, follow all of the following steps.\n\n1. If `pulumi` is not already installed, install the CLI following instructions [here](https://www.pulumi.com/docs/iac/download-install/).\n   After installing for the first time, restart your terminal and run:\n   ```bash\n   pulumi login --local  # omit --local to use Pulumi Cloud (requires separate account)\n   ```\n\n2. Clone the template repository.\n\n   ```bash\n   git clone https://github.com/datarobot-community/talk-to-my-data-agent.git\n   cd talk-to-my-data-agent\n   ```\n\n3. Rename the file `.env.template` to `.env` in the root directory of the repo and populate your credentials.",
                    "2": "```bash\n   DATAROBOT_API_TOKEN=...\n   DATAROBOT_ENDPOINT=...  # e.g. https://app.datarobot.com/api/v2\n   OPENAI_API_KEY=...\n   OPENAI_API_VERSION=...  # e.g. 2024-02-01\n   OPENAI_API_BASE=...  # e.g. https://your_org.openai.azure.com/\n   OPENAI_API_DEPLOYMENT_ID=...  # e.g. gpt-4o\n   PULUMI_CONFIG_PASSPHRASE=...  # Required. Choose your own alphanumeric passphrase to be used for encrypting pulumi config\n   FRONTEND_TYPE=...  # Optional. Default is \"streamlit\". Set to \"react\" to use React frontend\n   ```\n   Use the following resources to locate the required credentials:\n   - **DataRobot API Token**: Refer to the *Create a DataRobot API Key* section of the [DataRobot API Quickstart docs](https://docs.datarobot.com/en/docs/api/api-quickstart/index.html#create-a-datarobot-api-key).\n   - **DataRobot Endpoint**: Refer to the *Retrieve the API Endpoint* section of the same [DataRobot API Quickstart docs](https://docs.datarobot.com/en/docs/api/api-quickstart/index.html#retrieve-the-api-endpoint).\n   - **LLM Endpoint and API Key**: Refer to the [Azure OpenAI documentation](https://learn.microsoft.com/en-us/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line%2Cjavascript-keyless%2Ctypescript-keyless%2Cpython-new&pivots=programming-language-python#retrieve-key-and-endpoint).\n\n4. In a terminal, run:\n   ```bash\n   python quickstart.py YOUR_PROJECT_NAME  # Windows users may have to use `py` instead of `python`\n   ```\n   Python 3.10 - 12 are supported\n\n\nAdvanced users desiring control over virtual environment creation, dependency installation, environment variable setup\nand `pulumi` invocation see [here](#setup-for-advanced-users).\n\n## Architecture overview\n\n![image](https://s3.us-east-1.amazonaws.com/datarobot_public/drx/ttmd2-schematic.jpg)\n\n\nApp templates contain three families of complementary logic:\n\n- **AI logic**: Necessary to service AI requests and produce predictions and completions.\n  ```\n  deployment_*/  # Chat agent model\n  ```\n- **App Logic**: Necessary for user consumption; whether via a hosted front-end or integrating into an external consumption layer.\n  ```\n  frontend/  # Streamlit frontend\n  frontend_react/  # React frontend alternative\n  utils/  # App business logic & runtime helpers\n  ```\n- **Operational Logic**: Necessary to activate DataRobot assets.\n  ```\n  infra/__main__.py  # Pulumi program for configuring DataRobot to serve and monitor AI and app logic\n  infra/  # Settings for resources and assets created in DataRobot\n  ```\n\n## Why build AI Apps with DataRobot app templates?",
                    "3": "App Templates transform your AI projects from notebooks to production-ready applications. Too often, getting models into production means rewriting code, juggling credentials, and coordinating with multiple tools and teams just to make simple changes. DataRobot's composable AI apps framework eliminates these bottlenecks, letting you spend more time experimenting with your ML and app logic and less time wrestling with plumbing and deployment.\n- Start building in minutes: Deploy complete AI applications instantly, then customize the AI logic or the front-end independently (no architectural rewrites needed).\n- Keep working your way: Data scientists keep working in notebooks, developers in IDEs, and configs stay isolated. Update any piece without breaking others.\n- Iterate with confidence: Make changes locally and deploy with confidence. Spend less time writing and troubleshooting plumbing and more time improving your app.\n\nEach template provides an end-to-end AI architecture, from raw inputs to deployed application, while remaining highly customizable for specific business requirements.\n\n## Data privacy\nYour data privacy is important to us. Data handling is governed by the DataRobot [Privacy Policy](https://www.datarobot.com/privacy/), please review before using your own data with DataRobot.\n\n\n## Make changes\n\n### Change the frontend\n\nThe Talk to My Data agent supports two frontend options:\n\n1. Streamlit frontend (default): A Python-based frontend with a simple interface\n2. React frontend: A modern JavaScript-based frontend with enhanced UI features\n\nTo change the frontend:\n\n1. In `.env`: Set `FRONTEND_TYPE=\"react\"` to use the React frontend instead of the default Streamlit frontend\n2. Run `pulumi up` to update your stack (Or rerun your quickstart)\n   ```bash\n   source set_env.sh  # On windows use `set_env.bat`\n   pulumi up\n   ```\n\n> **\u26a0\ufe0f Important note:**  \n> If you make changes to the React frontend code, you need to rebuild it before deploying:\n> ```bash\n> cd frontend_react/react_src\n> npm install\n> npm run build\n> ```\n> The built files will be placed in `frontend_react/deploy/dist/` which will be used by the deployment. See `frontend_react/react_src/README.md` for more details on developing and building the React frontend.\n\n### Change the LLM",
                    "4": "1. Modify the `LLM` setting in `infra/settings_generative.py` by changing `LLM=LLMs.AZURE_OPENAI_GPT_4_O` to any other LLM from the `LLMs` object. \n     - Trial users: Please set `LLM=LLMs.AZURE_OPENAI_GPT_4_O_MINI` since GPT-4o is not supported in the trial. Use the `OPENAI_API_DEPLOYMENT_ID` in `.env` to override which model is used in your azure organisation. You'll still see GPT 4o-mini in the playground, but the deployed app will use the provided azure deployment.  \n2. To use an existing TextGen model or deployment:\n      - In `infra/settings_generative.py`: Set `LLM=LLMs.DEPLOYED_LLM`.\n      - In `.env`: Set either the `TEXTGEN_REGISTERED_MODEL_ID` or the `TEXTGEN_DEPLOYMENT_ID`\n      - In `.env`: Set `CHAT_MODEL_NAME` to the model name expected by the deployment (e.g. \"claude-3-7-sonnet-20250219\" for an anthropic deployment, \"datarobot-deployed-llm\" for NIM models ) \n      - (Optional) In `utils/api.py`: `ALTERNATIVE_LLM_BIG` and `ALTERNATIVE_LLM_SMALL` can be used for fine-grained control over which LLM is used for different tasks.\n3. In `.env`: If not using an existing TextGen model or deployment, provide the required credentials dependent on your choice.\n4. Run `pulumi up` to update your stack (Or rerun your quickstart).\n      ```bash\n      source set_env.sh  # On windows use `set_env.bat`\n      pulumi up\n      ```\n\n> **\u26a0\ufe0f Availability information:**  \n> Using a NIM model requires custom model GPU inference, a premium feature. You will experience errors by using this type of model without the feature enabled. Contact your DataRobot representative or administrator for information on enabling this feature.\n\n### Change the database\n\n#### Snowflake\n\nTo add Snowflake support:\n\n1. Modify the `DATABASE_CONNECTION_TYPE` setting in `infra/settings_database.py` by changing `DATABASE_CONNECTION_TYPE = \"no_database\"` to `DATABASE_CONNECTION_TYPE = \"snowflake\"`.\n2. Provide snowflake credentials in `.env` by either setting `SNOWFLAKE_USER` and `SNOWFLAKE_PASSWORD` or by setting `SNOWFLAKE_KEY_PATH` to a file containing the key. The key file should be a `*.p8` private key file. (see [Snowflake Documentation](https://docs.snowflake.com/en/user-guide/key-pair-auth))\n3. Fill out the remaining snowflake connection settings in `.env` (refer to `.env.template` for more details)\n4. Run `pulumi up` to update your stack (Or re-run the quickstart).\n      ```bash\n      source set_env.sh  # On windows use `set_env.bat`\n      pulumi up\n      ```\n \n#### BigQuery",
                    "5": "The Talk to my Data Agent supports connecting to BigQuery.\n1. Modify the `DATABASE_CONNECTION_TYPE` setting in `infra/settings_database.py` by changing `DATABASE_CONNECTION_TYPE = \"no_database\"` to `DATABASE_CONNECTION_TYPE = \"bigquery\"`. \n2. Provide the required google credentials in `.env` dependent on your choice.  Ensure that GOOGLE_DB_SCHEMA is also populated in `.env`.\n3. Run `pulumi up` to update your stack (Or rerun your quickstart).\n      ```bash\n      source set_env.sh  # On windows use `set_env.bat`\n      pulumi up\n      ```\n#### SAP Datasphere\n\nThe Talk to my Data Agent supports connecting to SAP Datasphere.\n1. Modify the `DATABASE_CONNECTION_TYPE` setting in `infra/settings_database.py` by changing `DATABASE_CONNECTION_TYPE = \"no_database\"` to `DATABASE_CONNECTION_TYPE = \"sap\"`. \n2. Provide the required SAP credentials in `.env`.\n3. Run `pulumi up` to update your stack (Or rerun your quickstart).\n      ```bash\n      source set_env.sh  # On windows use `set_env.bat`\n      pulumi up\n      ```\n\n## Tools\n\nYou can help the data analyst python agent by providing tools that can assist with data analysis tasks. For that, define functions in `utils/tools.py`. The function will be made available inside the code execution environment of the agent. The name, docstring and signature will be provided to the agent inside the prompt.\n\n## Share results\n\n1. Log into the DataRobot application.\n2. Navigate to **Registry > Applications**.\n3. Navigate to the application you want to share, open the actions menu, and select **Share** from the dropdown.\n\n## Delete all provisioned resources\n\n```bash\npulumi down\n```\n\n## Setup for advanced users\nFor manual control over the setup process adapt the following steps for MacOS/Linux to your environment:\n```bash\npython -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\nsource set_env.sh\npulumi stack init YOUR_PROJECT_NAME\npulumi up \n```\ne.g. for Windows/conda/cmd.exe this would be:\n```bash\nconda create --prefix .venv pip\nconda activate .\\.venv\npip install -r requirements.txt\nset_env.bat\npulumi stack init YOUR_PROJECT_NAME\npulumi up\n```\nFor projects that will be maintained, DataRobot recommends forking the repo so upstream fixes and improvements can be merged in the future."
                },
                "file_path": ".data/storage/uploads/1/fb0d2ebf-525b-4c0b-8805-17e9ce0c8e13/sample_project_readme.txt",
                "filename": "sample_project_readme.txt",
                "owner_uuid": "6b3823a1-82dc-4021-b3c9-19d38ffbe21d",
                "size_tokens": 3066,
                "source": "local",
                "uuid": "c32d4ae7-2aa3-43c3-8646-f6b9ea0da068"
            },
            {
                "created_at": "2025-09-11T18:54:34.674607Z",
                "encoded_content": {
                    "1": "",
                    "10": "Why the usual isn\u2019t enough\nParallelization\nOnly so many cores, shared services\nMore servers, more problems\nSetup time starts to dominate testing time\n$$$$$\nRun most tests nightly instead of per PR\nToo much change in a given day, git bisect can take >6 hours for one failed test and doesn\u2019t work with flaky tests\nStaging/CI system broken more frequently\nReduce tests run per change with highly cohesive tests and code\nChallenging to enforce clean dependency graphs\nLess cross dependency testing = more broken things\n\n",
                    "11": "Let\u2019s Use testmon!\n\u2705 Reduces number of tests for a given PR based on changes\n\n\u2705 Less tests = less runtime\n\n\u2705 Selecting the right tests means irrelevant broken tests are not run\n",
                    "12": "Let\u2019s Use testmon!",
                    "13": "Scaling testmon\nWhy it doesn\u2019t work\nHow we scaled it\n...How we scaled it\n...Really, how we scaled it",
                    "14": "Why it doesn\u2019t work\nDesigned to speed local development, not CI level\nRequires you to run all tests to populate DB\nDatabase is SQLite and needs to get distributed to build nodes\nOnce distributed to build node, SQLite is single writer\nNon-code file changes break tests\nNot ready for millions of lines of code\n",
                    "15": "How we scaled it: Making Swift Mode\nCreated Script for managing DBs\nS3 Storage of DB\nMerging of executor build DBs\nCreated dedicated Jenkins jobs for updating DB\nMade Pytest plugin to export selected tests \nEnable xdist and Cythonization\nCreated \ud83d\udd0aSmart Test Entropy Rule Engine Override \ud83d\udd0a \nPytest-plugin that lets you override testmon\u2019s selections and select them anyway\nPlugin based architecture, one plugin: file-glob\nEnable configuration in PR Templates to enable/disable testmon for a PR",
                    "16": "Update DB Process\nHow we scaled it - Swift Mode v0\nRun Tests",
                    "17": "Update DB Process\nHow we scaled it - Swift Mode v0\nRun Tests",
                    "18": "Update DB Process\n...How we scaled it\nRun Tests",
                    "19": "...Really, how we scaled it - Swift Mode v1\nForked: https://github.com/datarobot/pytest-testmon/\n\nSignificant DB schema and pragma changes, i.e. page through the 10 million+ dependency graph edges instead of all in one\nCode block fingerprinting performance improvements\nTurns out finding comment and blanks lines 35% faster using strip over regex on 2 million lines really matters\nStopped sorting tests by runtime (took >5 minutes to sort 34,000 tests)\nALL the memory optimizations",
                    "2": "Swift Mode\nDragging pytest-testmon up to DataRobot scale\nCarson Gee",
                    "20": "...Really, how we scaled it - Swift Mode v1\nUpdates:\nScaled update server count\nSQL optimizations for merging executor DBs\nXZ compression of DBs for transit speedup (Thanks DevInfra!)\n\nPRs/DTS:\nCreated EngProd Service for fast degradation\nRandomized test ID detection, URL encoded test names\nAdded changed-tests plugin to pytest-STEREO\nAutoFCS and EngProd App detection of Swift Mode skipped tests (Thanks EngProd Squad!)",
                    "21": "Results and Next Steps\nWas it worth it?\nNext steps\u2026?",
                    "22": "Was it Worth it?\nNumber of Tests Run on PRs - Before",
                    "23": "Number of Tests Run on PRs - After",
                    "24": "Was it worth it?\nYes (probably)!\nWe run about 70% less tests\nRuntime down about 30% on average\nSaving ~$600 USD/day\n...\nCoupled tests exposed!\nMaster breaks more often!",
                    "25": "Next Steps\u2026?\nSpeed up PRs:\nUtilize dependency graph in fan out test scheduling\nFaster update cycles to reduce drift from master\nExperiment with using a graph database\n\nBreak CI Pipelines Less less:\nAutomate correcting dependency graph selection failures\nResolve coverage.py/Python caching issues",
                    "26": "Questions?",
                    "3": "Overview \nWhy use testmon?\nScaling testmon to Swift Mode\nResults and next steps",
                    "4": "Overview\nWho am I?\nWhat is pytest-testmon?",
                    "5": "Who am I? Carson Gee\nReally Full Stack (i.e. Easily distracted)\nWorked on Cool Stuff\nHelped NASA map out what is under the ice in Antarctica, Greenland, and Mars\nServed on Architects Council for Open edX\nBrought the Copenhagen Wheel to market (e-bike conversion kit)\nBuilt an AR enabled social network out of backpacks, hats, and even duct tape\nHelped DataRobot run ~70% less unit/integration tests\nLoves \ud83d\udc0d, \ud83d\udeb2 ,  \ud83d\udc36, and \ud83c\udf7a\n",
                    "6": "What is pytest-testmon?\nOpen source plugin for the Python test runner pytest\nTestmon selects tests affected by changed files and methods\nUses coverage.py to record the code a test exercises\nUses recordings from previous runs to determine what changed and what tests should run\n",
                    "7": "Pytest with testmon flow",
                    "8": "Why testmon?\nWait, how many tests?!\nWhy the usual isn\u2019t enough",
                    "9": "Wait, how many tests?!\nNo one wants to wait four days to test a\n twenty line change\n\nWhy four days you ask? Oh hi there monorepo!\n12,604,434 lines of code (~2,000,000 Python)\n>100,000 commits, ~70,000 PRs\n150,000+ tests run on main branch merge\nRun same tests in multiple configurations and environments (Py2/3, Kubernetes/Hadoop, etc.)"
                },
                "file_path": ".data/storage/uploads/1/fb0d2ebf-525b-4c0b-8805-17e9ce0c8e13/sample_dev_preso.pptx",
                "filename": "sample_dev_preso.pptx",
                "owner_uuid": "6b3823a1-82dc-4021-b3c9-19d38ffbe21d",
                "size_tokens": 1149,
                "source": "local",
                "uuid": "58ce6dfb-c437-483c-80e3-a344315868d3"
            },
            {
                "created_at": "2025-09-11T18:54:35.342161Z",
                "encoded_content": {
                    "1": "",
                    "10": "Con\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\nWhy the usual isn\u2019t enough\n\u2022\nParallelization\n\u2022\nOnly so many cores, shared services\n\u2022\nMore servers, more problems\n\u2022\nSetup time starts to dominate testing time\n\u2022\n$$$$$\n\u2022\nRun most tests nightly instead of per PR\n\u2022\nToo much change in a given day, git bisect can take >6 hours for one failed \ntest and doesn\u2019t work with \ufb02aky tests\n\u2022\nStaging/CI system broken more frequently\n\u2022\nReduce tests run per change with highly cohesive tests and code\n\u2022\nChallenging to enforce clean dependency graphs\n\u2022\nLess cross dependency testing = more broken things\n",
                    "11": "Con\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\nLet\u2019s Use testmon!\n\u2705 Reduces number of tests for a given PR based on changes\n\u2705 Less tests = less runtime\n\u2705 Selecting the right tests means irrelevant broken tests are not \nrun\n",
                    "12": "Con\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\nLet\u2019s Use testmon!\n",
                    "13": "Con\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\nScaling \ntestmon\n1.\nWhy it doesn\u2019t work\n2.\nHow we scaled it\n3.\n...How we scaled it\n4.\n...Really, how we scaled it\n",
                    "14": "Con\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\nWhy it doesn\u2019t work\n\u2022\nDesigned to speed local development, not CI level\n\u2022\nRequires you to run all tests to populate DB\n\u2022\nDatabase is SQLite and needs to get distributed to build nodes\n\u2022\nOnce distributed to build node, SQLite is single writer\n\u2022\nNon-code \ufb01le changes break tests\n\u2022\nNot ready for millions of lines of code\n",
                    "15": "Con\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\nHow we scaled it: Making Swift Mode\n\u2022\nCreated Script for managing DBs\n\u2022\nS3 Storage of DB\n\u2022\nMerging of executor build DBs\n\u2022\nCreated dedicated Jenkins jobs for updating DB\n\u2022\nMade Pytest plugin to export selected tests \n\u2022\nEnable xdist and Cythonization\n\u2022\nCreated \ud83d\udd0aSmart Test Entropy Rule Engine Override \ud83d\udd0a \n\u2022\nPytest-plugin that lets you override testmon\u2019s selections and select them \nanyway\n\u2022\nPlugin based architecture, one plugin: \ufb01le-glob\n\u2022\nEnable con\ufb01guration in PR Templates to enable/disable testmon for \na PR\n",
                    "16": "Con\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\nUpdate DB Process\nHow we scaled it - Swift Mode v0\nRun Tests\n",
                    "17": "Con\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\nUpdate DB Process\nHow we scaled it - Swift Mode v0\nRun Tests\n",
                    "18": "Con\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\nUpdate DB Process\n...How we scaled it\nRun Tests\n",
                    "19": "Con\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\n...Really, how we scaled it - Swift Mode v1\nForked: https://github.com/datarobot/pytest-testmon/\n\u2022\nSigni\ufb01cant DB schema and pragma changes, i.e. page through the \n10 million+ dependency graph edges instead of all in one\n\u2022\nCode block \ufb01ngerprinting performance improvements\n\u2022\nTurns out \ufb01nding comment and blanks lines 35% faster using strip over regex \non 2 million lines really matters\n\u2022\nStopped sorting tests by runtime (took >5 minutes to sort 34,000 \ntests)\n\u2022\nALL the memory optimizations\n",
                    "2": "Con\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\nSwift Mode\nDragging pytest-testmon up \nto DataRobot scale\nCarson Gee\n",
                    "20": "Con\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\n...Really, how we scaled it - Swift Mode v1\nUpdates:\n\u2022\nScaled update server count\n\u2022\nSQL optimizations for merging executor DBs\n\u2022\nXZ compression of DBs for transit speedup (Thanks DevInfra!)\nPRs/DTS:\n\u2022\nCreated EngProd Service for fast degradation\n\u2022\nRandomized test ID detection, URL encoded test names\n\u2022\nAdded changed-tests plugin to pytest-STEREO\n\u2022\nAutoFCS and EngProd App detection of Swift Mode skipped tests \n(Thanks EngProd Squad!)\n",
                    "21": "Con\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\nResults \nand Next \nSteps\n1.\nWas it worth it?\n2.\nNext steps\u2026?\n",
                    "22": "Con\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\nWas it Worth it?\nNumber of Tests Run on PRs - Before\n",
                    "23": "Con\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\nNumber of Tests Run on PRs - After\n",
                    "24": "Con\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\nWas it worth it?\nYes (probably)!\n\u2022\nWe run about 70% less tests\n\u2022\nRuntime down about 30% on average\n\u2022\nSaving ~$600 USD/day\n...\n\u2022\nCoupled tests exposed!\n\u2022\nMaster breaks more often!\n",
                    "25": "Con\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\nNext Steps\u2026?\nSpeed up PRs:\n\u2022\nUtilize dependency graph in fan out test scheduling\n\u2022\nFaster update cycles to reduce drift from master\n\u2022\nExperiment with using a graph database\nBreak CI Pipelines Less less:\n\u2022\nAutomate correcting dependency graph selection failures\n\u2022\nResolve coverage.py/Python caching issues\n",
                    "26": "Con\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\nQuestions?\n",
                    "3": "Agenda\nCon\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\n1.\nOverview \n2.\nWhy use testmon?\n3.\nScaling testmon to Swift Mode\n4.\nResults and next steps\n",
                    "4": "Con\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\nOverview\n1.\nWho am I?\n2.\nWhat is pytest-testmon?\n",
                    "5": "Con\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\nWho am I? Carson Gee\n\u2022\nReally Full Stack (i.e. Easily distracted)\n\u2022\nWorked on Cool Stuff\n\u2022\nHelped NASA map out what is under the ice in \nAntarctica, Greenland, and Mars\n\u2022\nServed on Architects Council for Open edX\n\u2022\nBrought the Copenhagen Wheel to market (e-bike \nconversion kit)\n\u2022\nBuilt an AR enabled social network out of backpacks, \nhats, and even duct tape\n\u2022\nHelped DataRobot run ~70% less unit/integration tests\n\u2022\nLoves \ud83d\udc0d, \ud83d\udeb2 ,  \ud83d\udc36, and \ud83c\udf7a\n",
                    "6": "Con\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\nWhat is pytest-testmon?\n\u2022\nOpen source plugin for the Python test runner pytest\n\u2022\nTestmon selects tests affected by changed \ufb01les and methods\n\u2022\nUses coverage.py to record the code a test exercises\n\u2022\nUses recordings from previous runs to determine what changed and \nwhat tests should run\n",
                    "7": "Con\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\nPytest with testmon \ufb02ow\n",
                    "8": "Con\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\nWhy \ntestmon?\n1.\nWait, how many tests?!\n2.\nWhy the usual isn\u2019t enough\n",
                    "9": "Con\ufb01dential. \u00a92020 DataRobot, Inc. \u2013 All rights reserved\nWait, how many tests?!\nNo one wants to wait four days to test a\n twenty line change\nWhy four days you ask? Oh hi there monorepo!\n\u2022\n12,604,434 lines of code (~2,000,000 Python)\n\u2022\n>100,000 commits, ~70,000 PRs\n\u2022\n150,000+ tests run on main branch merge\n\u2022\nRun same tests in multiple con\ufb01gurations and environments (Py2/3, \nKubernetes/Hadoop, etc.)\n"
                },
                "file_path": ".data/storage/uploads/1/fb0d2ebf-525b-4c0b-8805-17e9ce0c8e13/sample_dev_preso.pdf",
                "filename": "sample_dev_preso.pdf",
                "owner_uuid": "6b3823a1-82dc-4021-b3c9-19d38ffbe21d",
                "size_tokens": 1556,
                "source": "local",
                "uuid": "1ca73372-e477-43f7-892c-c768ee55df5f"
            }
        ],
        "is_public": false,
        "owner_uuid": "6b3823a1-82dc-4021-b3c9-19d38ffbe21d",
        "path": "1/fb0d2ebf-525b-4c0b-8805-17e9ce0c8e13",
        "title": "Developer Documents",
        "token_count": 7892,
        "updated_at": "2025-09-11T18:54:49.845760Z",
        "uuid": "fb0d2ebf-525b-4c0b-8805-17e9ce0c8e13"
    },
    "question": "Give me a quick summary of the yaml spec and the tech spec",
    "topic": "A variety of developer documents"
}